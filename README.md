# Walking-Running
#### A better understanding of Recurrent neural networks(RNN) and Long short term memory(LSTM) networks was imperative for the execution of this project. Several articles and videos pertinent to the same was explored for achieving this. We understood that an LSTM network is a type of RNN, which is capable of learning order dependence especially in sequence prediction problems. They use information from previous steps along with new information to carry out the predictions.

#### The dataset given comprises of accelerometer and gyroscope readings for each of the sensor's axes, thus making a total of 6 independent variables or predictors.

#### The pairplot function from seaborn was used inorder to visualize the realationship between each of the predictors so as to detect any kind of correlation between them, which in this case, was absent.Then, boxplots where used to detect the outliers in the data. Even though there were several points outside the inter-quartile range, they were clustered together and were not taken as outliers. However, the isolated points at the extremities were eliminated and imputed with the mean value. Skewness was checked using the histplot function from matplotlib. It was observed that most of the features are almost normally distributed.Applying log, square root or cube root transformations were unsuccessful as skewness of one or more features increased as the others decreased. So the skewness was left as such. The count plot showed an equillibrium of the values of target variable in the given dataset. Feature importances were measured by utilizing the XGBclassifier from xgboost and 'accelerometer_y' and 'gyro_y' had the maximum and minimum values respectively.

#### Data pre-processing involved eliminating redundant variables('username','date','time','wrist') and splitting the predictor and target variable into x and y respectively.This was further split into training and testing dataset for model training and evaluation. The data was normalized using the StandardScaler package from scikit learn inorder to reduce the computational complexity.

#### Model was built using the Sequential,LSTM,Dropout and Dense functions from the keras API. Two LSTM layers, each with 100 units one dropout layer with a rate of 0.2 to prevent overfitting and one Dense layer using 'softmax' activation for classification was used to build the model.Model was compiled with sparse categorical cross entropy as the loss function, accuracy as the evaluation metric and Adam as the optimizer. After running the model upto 20 epochs at a batch size of 32 and a validation split of 20% using the training data, a validation accuracy of 99.1% was achieved.This was followed by saving the model, loading it and then tesing it using the test data, where we achieved an accuracy of ~99.165%.
